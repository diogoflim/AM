{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "312233b5",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/diogoflim/AM/blob/main/6_DeepLearning/aula_DL.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c21e6e8-ca56-42bd-9f00-6409f8a17dca",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Aprendizado de máquina e decisões dirigidas por dados\n",
    "\n",
    "**Professor: Diogo Ferreira de Lima Silva**\n",
    "\n",
    "**TPP - UFF**\n",
    "\n",
    "**Aula 6 e 7**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Redes Neurais"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Revisão das últimas aulas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estudamos nas últimas aulas o modelo Perceptron, conhecido como o modelo básico de redes neurais. Vimos que\n",
    "\n",
    "- O Perceptron, assim como uma regressão linear ou uma regressão logística, pode ser visto como uma rede de: \n",
    "\n",
    "    - uma camada de input, representada pelos atributos das observações de treinamento.\n",
    "    - uma camada escondida com um único neurônio que recebe a soma ponderada dos valores dos atributos pelos respectivos pessos.\n",
    "        - observação: também há um atributo conhecido como bias $(b)$.\n",
    "    - Na camada escondida, realiza-se uma operação designada pela função de ativação a depender do modelo utilizado.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A figura abaixo ilustra a situação:\n",
    "\n",
    "<img src=\"fig_1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As funções de ativação para os casos estudados seriam:\n",
    "\n",
    "- Regressão Linear: $a = g(z)=z$\n",
    "\n",
    "- Regressão Logística: $a = g(z)=\\frac{1}{1+e^{-z}}$\n",
    "\n",
    "    - Nesse caso: \n",
    "    \n",
    "    $$y = \\begin{cases} 1 & \\text{se } a > 0.5 \\\\ 0 & \\text{caso contrário} \\end{cases}$$\n",
    "\n",
    "- Perceptron: $a = g(z)=z$\n",
    "    - Nesse caso: \n",
    "    \n",
    "    $$y = \\begin{cases} 1 & \\text{se } a >= 0 \\\\ -1 & \\text{caso contrário} \\end{cases}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Múltiplas Camadas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalmente, o estudo de redes neurais trata de problemas onde é interessante a utilização de múltiplas camadas escondidas. Nesse caso, nosso algoritmo de aprendizagem ganha a capacidade de aprender funções mais complexas. \n",
    "\n",
    "Adicionamente, várias outras possibilidades de funções de ativação podem ser utilizadas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arquitetura de uma Rede Neural"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em uma RNA, os neurônios podem estar dispostos em mais de uma camada intermediária. \n",
    "\n",
    "- Saídas dos neurônios de uma camada intermediária podem ser entradas para os neurônios da camada intermediária seguinte. \n",
    "- Saídas dos neurônios da última camada intermediária são entradas para neurônios dispostos em uma camada de saída (output). \n",
    "\n",
    "Quando há mais de uma camada intermediária, a rede neural é chamada de rede multicamadas (redes profundas). \n",
    "\n",
    "Vejamos um exemplo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"fig_2.png\">\n",
    "\n",
    "Nessa figura, apenas alguns arcos foram desenhados para simplificar a visualização. No entanto, perceba que a partir de um neurônio na camada $l$ poderia sair um link para cada neurônio da camada $l+1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vejamos uma representação simplificada da rede acima, porém, considere que temos todos os links propagados.\n",
    "\n",
    "<img src = \"fig_3.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vetor $\\vec{a}^{[0]} = \\vec{x} = [x_1, x_2, ..., x_n]$.\n",
    "\n",
    "---\n",
    "\n",
    "Vetor $\\vec{a}^{[1]}$:\n",
    "\n",
    "$$ a^{[1]}_1 =  g^{[1]}(\\vec{w}^{[1]}_1 \\cdot \\vec{x} + b^{[1]}_1) $$\n",
    "$$ a^{[1]}_2 =  g^{[1]}(\\vec{w}^{[1]}_2 \\cdot \\vec{x} + b^{[1]}_2) $$\n",
    "$$ a^{[1]}_3 =  g^{[1]}(\\vec{w}^{[1]}_3 \\cdot \\vec{x} + b^{[1]}_3) $$\n",
    "\n",
    "--------\n",
    "\n",
    "Vetor $\\vec{a}^{[2]}$:\n",
    "\n",
    "$$ a^{[2]}_1 =  g^{[2]}(\\vec{w}^{[2]}_1 \\cdot \\vec{a}^{[1]} + b^{[2]}_1) $$\n",
    "$$ a^{[2]}_2 =  g^{[2]}(\\vec{w}^{[2]}_2 \\cdot \\vec{a}^{[1]} + b^{[2]}_2) $$\n",
    "$$ a^{[2]}_3 =  g^{[2]}(\\vec{w}^{[2]}_3 \\cdot \\vec{a}^{[1]} + b^{[2]}_3) $$\n",
    "$$ a^{[2]}_4 =  g^{[2]}(\\vec{w}^{[2]}_4 \\cdot \\vec{a}^{[1]} + b^{[2]}_4) $$\n",
    "\n",
    "--------\n",
    "\n",
    "Vetor $\\vec{a}^{[3]}$:\n",
    "\n",
    "$$ a^{[3]}_1 =  g^{[3]}(\\vec{w}^{[3]}_1 \\cdot \\vec{a}^{[2]} + b^{[3]}_1) $$\n",
    "$$ a^{[3]}_2 =  g^{[3]}(\\vec{w}^{[3]}_2 \\cdot \\vec{a}^{[2]} + b^{[3]}_2) $$\n",
    "\n",
    "--------\n",
    "\n",
    "De maneira geral, a notação fica:\n",
    "\n",
    "$$ a^{[l]}_j =  g^{[l]}(\\vec{w}^{[l]}_j \\cdot \\vec{a}^{[l-1]} + b^{[l]}_j) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perceba que, na notação que estudamos até o momento, estamos tratando da passagem de um exemplo (um vetor $\\vec{x}$ específico) pela rede. \n",
    "\n",
    "Porém, na verdade uma matriz de exemplos de treinamento $\\mathbf{X}$ deve passar pela rede para o cálculo do custo após cada iteração.\n",
    "\n",
    "**Vamos iniciar um primeiro exemplo no Tensorflow**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow\n",
    "\n",
    "O TensorFlow é uma das principais bibliotecas para implementação de algorítmos de redes neurais. \n",
    "\n",
    "Vejamos como ficaria o exemplo de uma rede neural de 3 camadas escondidas implementado no TensorFlow:\n",
    "\n",
    "- Camada 1 com 3 neurônios\n",
    "- Camada 2 com 4 neurônios\n",
    "- Camada 3 com 1 neurônio\n",
    "- As funções de ativação em todas as camadas são sigmoides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando as bibliotecas\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(1234) \n",
    "\n",
    "modelo = Sequential(\n",
    "    [\n",
    "        Dense(3, activation='sigmoid', name = 'camada_1'),\n",
    "        Dense(4, activation='sigmoid', name = 'camada_2'),\n",
    "        Dense(1, activation='sigmoid', name = 'camada_3')\n",
    "     ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos criar um Dataset para testar nosso modelo. \n",
    "O problema tratado será de duas classes. Usaremos a função do sklearn makeblobs para criar o dataset com as seguintes características:\n",
    "- 2 classes\n",
    "- 3 atributos\n",
    "- 1000 exemplos\n",
    "\n",
    "Informações: https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_blobs.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "classes = 2\n",
    "m = 1000\n",
    "centers = [[-5, -5, -5], [5, 5, 5]]\n",
    "std = 7.0\n",
    "X_train, y_train = make_blobs(n_samples=m, centers=centers, cluster_std=std,random_state=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -8.27589418,  -6.00601927,   1.72422202],\n",
       "       [  3.2905861 ,  -5.74092333,  -9.73150057],\n",
       "       [  3.33428541,   6.25081248,   8.16387198],\n",
       "       ...,\n",
       "       [ -3.16434604,   7.56162468,   2.14345937],\n",
       "       [  1.37071913,   0.19911344,  -1.15212557],\n",
       "       [-15.20994896,  -1.29901339,  -5.17813762]])"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1,\n",
       "       0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1,\n",
       "       0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "       0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0,\n",
       "       0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0,\n",
       "       0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0,\n",
       "       0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0,\n",
       "       0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0,\n",
       "       0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1,\n",
       "       1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "       0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1,\n",
       "       0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0,\n",
       "       0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0,\n",
       "       0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1,\n",
       "       0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1,\n",
       "       1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1,\n",
       "       1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1,\n",
       "       0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1,\n",
       "       1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0,\n",
       "       1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1,\n",
       "       0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1,\n",
       "       0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0,\n",
       "       0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0,\n",
       "       1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0,\n",
       "       0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1,\n",
       "       1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0,\n",
       "       1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1,\n",
       "       1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0,\n",
       "       1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 0, 0])"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de exemplos na classe 0: 500\n",
      "Número de exemplos na classe 1: 500\n"
     ]
    }
   ],
   "source": [
    "contagem = np.bincount(y_train)\n",
    "print(f\"Número de exemplos na classe 0: {contagem[0]}\\nNúmero de exemplos na classe 1: {contagem[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Passando os exemplos para o treinamento do nosso modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo.compile(\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate = 0.01),\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "32/32 [==============================] - 2s 3ms/step - loss: 0.4019\n",
      "Epoch 2/20\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.3293\n",
      "Epoch 3/20\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2993\n",
      "Epoch 4/20\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2801\n",
      "Epoch 5/20\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2705\n",
      "Epoch 6/20\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2694\n",
      "Epoch 7/20\n",
      "32/32 [==============================] - 0s 2ms/step - loss: 0.2652\n",
      "Epoch 8/20\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2650\n",
      "Epoch 9/20\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2631\n",
      "Epoch 10/20\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2622\n",
      "Epoch 11/20\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2621\n",
      "Epoch 12/20\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2607\n",
      "Epoch 13/20\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2600\n",
      "Epoch 14/20\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2588\n",
      "Epoch 15/20\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2607\n",
      "Epoch 16/20\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2579\n",
      "Epoch 17/20\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2576\n",
      "Epoch 18/20\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2586\n",
      "Epoch 19/20\n",
      "32/32 [==============================] - 0s 4ms/step - loss: 0.2565\n",
      "Epoch 20/20\n",
      "32/32 [==============================] - 0s 3ms/step - loss: 0.2560\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ad7e7856a0>"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo.fit(\n",
    "    X_train,y_train,\n",
    "    epochs=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1:\n",
      " [[ 0.08334005 -0.29660565  0.17884266]\n",
      " [-0.56124383 -0.15262699  0.8899205 ]] \n",
      "b1: [0. 0. 0.]\n",
      "W2:\n",
      " [[-0.32336175 -0.66899645  0.27413416 -0.36288744]\n",
      " [-0.3022557  -0.68477273  0.38106263  0.40476227]\n",
      " [-0.20340782  0.56833684 -0.0420264   0.01816851]] \n",
      "b2: [0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "W1, b1 = model.get_layer(\"camada_1\").get_weights()\n",
    "W2, b2 = model.get_layer(\"camada_2\").get_weights()\n",
    "print(\"W1:\\n\", W1, \"\\nb1:\", b1)\n",
    "print(\"W2:\\n\", W2, \"\\nb2:\", b2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 0s 2ms/step\n",
      "As previsões para o valor da probabilidade de x_1 pertencer à classe 1 são: \n",
      "[[0.04334693]\n",
      " [0.05170152]\n",
      " [0.97126883]\n",
      " [0.8250412 ]\n",
      " [0.04154276]\n",
      " [0.97261715]\n",
      " [0.91044587]\n",
      " [0.9726982 ]\n",
      " [0.9726214 ]\n",
      " [0.26455694]\n",
      " [0.0420385 ]\n",
      " [0.36258042]\n",
      " [0.41928315]\n",
      " [0.95852584]\n",
      " [0.9675596 ]\n",
      " [0.06257364]\n",
      " [0.9724524 ]\n",
      " [0.9083154 ]\n",
      " [0.26694056]\n",
      " [0.9703758 ]\n",
      " [0.29617876]\n",
      " [0.95948684]\n",
      " [0.8161122 ]\n",
      " [0.95198697]\n",
      " [0.9692446 ]\n",
      " [0.0495991 ]\n",
      " [0.04989506]\n",
      " [0.9047513 ]\n",
      " [0.9715431 ]\n",
      " [0.09367179]\n",
      " [0.97261673]\n",
      " [0.9039258 ]\n",
      " [0.9685445 ]\n",
      " [0.09422315]\n",
      " [0.04889116]\n",
      " [0.14541432]\n",
      " [0.05300944]\n",
      " [0.046209  ]\n",
      " [0.05383921]\n",
      " [0.9725319 ]\n",
      " [0.8140064 ]\n",
      " [0.23604769]\n",
      " [0.04394041]\n",
      " [0.971887  ]\n",
      " [0.9722748 ]\n",
      " [0.05111042]\n",
      " [0.97216743]\n",
      " [0.97261363]\n",
      " [0.05993235]\n",
      " [0.9699938 ]\n",
      " [0.8994528 ]\n",
      " [0.9690667 ]\n",
      " [0.21814217]\n",
      " [0.0419695 ]\n",
      " [0.9069754 ]\n",
      " [0.93265176]\n",
      " [0.97058403]\n",
      " [0.9525049 ]\n",
      " [0.23801939]\n",
      " [0.3373496 ]\n",
      " [0.08268675]\n",
      " [0.96960574]\n",
      " [0.06887117]\n",
      " [0.05599405]\n",
      " [0.38602072]\n",
      " [0.7457423 ]\n",
      " [0.2868615 ]\n",
      " [0.97095406]\n",
      " [0.22267178]\n",
      " [0.04363906]\n",
      " [0.9721243 ]\n",
      " [0.04127924]\n",
      " [0.0414026 ]\n",
      " [0.90958834]\n",
      " [0.04131264]\n",
      " [0.9726988 ]\n",
      " [0.04120612]\n",
      " [0.06870217]\n",
      " [0.9631712 ]\n",
      " [0.9476466 ]\n",
      " [0.9483194 ]\n",
      " [0.04122078]\n",
      " [0.87626714]\n",
      " [0.97233135]\n",
      " [0.9726968 ]\n",
      " [0.93158615]\n",
      " [0.1939657 ]\n",
      " [0.04163902]\n",
      " [0.04119609]\n",
      " [0.56682575]\n",
      " [0.14748804]\n",
      " [0.9321264 ]\n",
      " [0.97271407]\n",
      " [0.04626912]\n",
      " [0.96632916]\n",
      " [0.7484055 ]\n",
      " [0.9608269 ]\n",
      " [0.04149335]\n",
      " [0.9690378 ]\n",
      " [0.04119638]\n",
      " [0.9015205 ]\n",
      " [0.04242133]\n",
      " [0.04222022]\n",
      " [0.9532147 ]\n",
      " [0.75901437]\n",
      " [0.9716583 ]\n",
      " [0.9390756 ]\n",
      " [0.9724434 ]\n",
      " [0.9658288 ]\n",
      " [0.9672926 ]\n",
      " [0.9544072 ]\n",
      " [0.04793882]\n",
      " [0.9721829 ]\n",
      " [0.8827592 ]\n",
      " [0.9727105 ]\n",
      " [0.0412019 ]\n",
      " [0.04617131]\n",
      " [0.97223645]\n",
      " [0.9162228 ]\n",
      " [0.971984  ]\n",
      " [0.04175881]\n",
      " [0.25755548]\n",
      " [0.05476878]\n",
      " [0.81949145]\n",
      " [0.41131952]\n",
      " [0.92094576]\n",
      " [0.9676443 ]\n",
      " [0.05207751]\n",
      " [0.8550211 ]\n",
      " [0.97240716]\n",
      " [0.9157195 ]\n",
      " [0.9726571 ]\n",
      " [0.46431357]\n",
      " [0.04122688]\n",
      " [0.04908783]\n",
      " [0.9632893 ]\n",
      " [0.9656918 ]\n",
      " [0.04637758]\n",
      " [0.18807983]\n",
      " [0.62881696]\n",
      " [0.9714671 ]\n",
      " [0.05420566]\n",
      " [0.72926307]\n",
      " [0.97268444]\n",
      " [0.9716642 ]\n",
      " [0.18310729]\n",
      " [0.17787267]\n",
      " [0.9705387 ]\n",
      " [0.04147672]\n",
      " [0.04176676]\n",
      " [0.97216994]\n",
      " [0.06732157]\n",
      " [0.04296889]\n",
      " [0.60113496]\n",
      " [0.11064147]\n",
      " [0.97238284]\n",
      " [0.91099787]\n",
      " [0.95675755]\n",
      " [0.9726095 ]\n",
      " [0.9725021 ]\n",
      " [0.94400936]\n",
      " [0.94373846]\n",
      " [0.0413152 ]\n",
      " [0.97235954]\n",
      " [0.97268707]\n",
      " [0.05239936]\n",
      " [0.06904183]\n",
      " [0.94803107]\n",
      " [0.04143966]\n",
      " [0.9700881 ]\n",
      " [0.97268516]\n",
      " [0.04587603]\n",
      " [0.0419494 ]\n",
      " [0.97262084]\n",
      " [0.73345536]\n",
      " [0.04124201]\n",
      " [0.04159622]\n",
      " [0.88846284]\n",
      " [0.04425528]\n",
      " [0.97271293]\n",
      " [0.9727012 ]\n",
      " [0.08469009]\n",
      " [0.07656913]\n",
      " [0.04143028]\n",
      " [0.9715736 ]\n",
      " [0.94142884]\n",
      " [0.21722478]\n",
      " [0.9727145 ]\n",
      " [0.32900137]\n",
      " [0.97194713]\n",
      " [0.9726655 ]\n",
      " [0.9725156 ]\n",
      " [0.9694696 ]\n",
      " [0.3700512 ]\n",
      " [0.04144245]\n",
      " [0.966412  ]\n",
      " [0.9725712 ]\n",
      " [0.04124151]\n",
      " [0.04506665]\n",
      " [0.96964103]\n",
      " [0.97251844]\n",
      " [0.97271323]\n",
      " [0.912319  ]\n",
      " [0.8934513 ]\n",
      " [0.96823704]\n",
      " [0.04169603]\n",
      " [0.97247386]\n",
      " [0.9726881 ]\n",
      " [0.04143491]\n",
      " [0.11061002]\n",
      " [0.97268176]\n",
      " [0.04194995]\n",
      " [0.04370441]\n",
      " [0.9696715 ]\n",
      " [0.04120753]\n",
      " [0.20439118]\n",
      " [0.9727076 ]\n",
      " [0.9093959 ]\n",
      " [0.97216046]\n",
      " [0.07595851]\n",
      " [0.05601292]\n",
      " [0.87041265]\n",
      " [0.9725381 ]\n",
      " [0.05666815]\n",
      " [0.05128208]\n",
      " [0.8402831 ]\n",
      " [0.7622869 ]\n",
      " [0.04188248]\n",
      " [0.20177494]\n",
      " [0.7739659 ]\n",
      " [0.05875642]\n",
      " [0.92916816]\n",
      " [0.8541022 ]\n",
      " [0.75335675]\n",
      " [0.9605879 ]\n",
      " [0.97260976]\n",
      " [0.97219896]\n",
      " [0.96245664]\n",
      " [0.04190186]\n",
      " [0.04141408]\n",
      " [0.07468951]\n",
      " [0.9671073 ]\n",
      " [0.35062626]\n",
      " [0.97182965]\n",
      " [0.04744618]\n",
      " [0.16804945]\n",
      " [0.9726635 ]\n",
      " [0.09585484]\n",
      " [0.04119268]\n",
      " [0.04121367]\n",
      " [0.04700433]\n",
      " [0.8394385 ]\n",
      " [0.05460966]\n",
      " [0.30554646]\n",
      " [0.05455997]\n",
      " [0.09119843]\n",
      " [0.08485302]\n",
      " [0.77992356]\n",
      " [0.04179196]\n",
      " [0.04124482]\n",
      " [0.9323873 ]\n",
      " [0.8364941 ]\n",
      " [0.04142059]\n",
      " [0.24939561]\n",
      " [0.0560668 ]\n",
      " [0.9702569 ]\n",
      " [0.20596366]\n",
      " [0.36869353]\n",
      " [0.11020341]\n",
      " [0.04139967]\n",
      " [0.04283097]\n",
      " [0.04137691]\n",
      " [0.9714663 ]\n",
      " [0.9727021 ]\n",
      " [0.3187489 ]\n",
      " [0.97157526]\n",
      " [0.19085097]\n",
      " [0.23799242]\n",
      " [0.05174646]\n",
      " [0.9607281 ]\n",
      " [0.9646442 ]\n",
      " [0.96607155]\n",
      " [0.04222332]\n",
      " [0.9665203 ]\n",
      " [0.04139041]\n",
      " [0.97202814]\n",
      " [0.972252  ]\n",
      " [0.04700805]\n",
      " [0.22796422]\n",
      " [0.20892453]\n",
      " [0.1565608 ]\n",
      " [0.40924126]\n",
      " [0.8789553 ]\n",
      " [0.9414778 ]\n",
      " [0.97246426]\n",
      " [0.04166051]\n",
      " [0.9150255 ]\n",
      " [0.97249526]\n",
      " [0.04164857]\n",
      " [0.90586305]\n",
      " [0.04566288]\n",
      " [0.04728577]\n",
      " [0.9726682 ]\n",
      " [0.04257671]\n",
      " [0.9717981 ]\n",
      " [0.04134108]\n",
      " [0.29697636]\n",
      " [0.04136054]\n",
      " [0.48071784]\n",
      " [0.04628265]\n",
      " [0.89797175]\n",
      " [0.9709419 ]\n",
      " [0.8330013 ]\n",
      " [0.9301181 ]\n",
      " [0.04257284]\n",
      " [0.15628898]\n",
      " [0.34493473]\n",
      " [0.04961533]\n",
      " [0.04675465]\n",
      " [0.972573  ]\n",
      " [0.97262704]\n",
      " [0.97136825]\n",
      " [0.7696276 ]\n",
      " [0.4281376 ]\n",
      " [0.97143203]\n",
      " [0.04259512]\n",
      " [0.26986587]\n",
      " [0.40983427]\n",
      " [0.9724931 ]\n",
      " [0.9725552 ]\n",
      " [0.06684615]\n",
      " [0.97236973]\n",
      " [0.5287217 ]\n",
      " [0.04403204]\n",
      " [0.04163792]\n",
      " [0.0433501 ]\n",
      " [0.9703792 ]\n",
      " [0.04122866]\n",
      " [0.31227946]\n",
      " [0.9517576 ]\n",
      " [0.18982601]\n",
      " [0.04195144]\n",
      " [0.8958743 ]\n",
      " [0.96648085]\n",
      " [0.2007482 ]\n",
      " [0.97265977]\n",
      " [0.04123149]\n",
      " [0.04120972]\n",
      " [0.21292098]\n",
      " [0.97270083]\n",
      " [0.9721709 ]\n",
      " [0.9721664 ]\n",
      " [0.04119372]\n",
      " [0.32201174]\n",
      " [0.84917355]\n",
      " [0.95874524]\n",
      " [0.1453616 ]\n",
      " [0.96497446]\n",
      " [0.89693373]\n",
      " [0.24035835]\n",
      " [0.64331   ]\n",
      " [0.51859295]\n",
      " [0.04149104]\n",
      " [0.12094095]\n",
      " [0.8383103 ]\n",
      " [0.04584679]\n",
      " [0.4541999 ]\n",
      " [0.30678838]\n",
      " [0.96925515]\n",
      " [0.04226985]\n",
      " [0.13022058]\n",
      " [0.04498044]\n",
      " [0.0418298 ]\n",
      " [0.06535494]\n",
      " [0.9727027 ]\n",
      " [0.27540237]\n",
      " [0.041262  ]\n",
      " [0.97225916]\n",
      " [0.04179208]\n",
      " [0.4731704 ]\n",
      " [0.9722525 ]\n",
      " [0.04858512]\n",
      " [0.04487047]\n",
      " [0.11338665]\n",
      " [0.1984412 ]\n",
      " [0.04203216]\n",
      " [0.04163363]\n",
      " [0.04312765]\n",
      " [0.3983056 ]\n",
      " [0.04259428]\n",
      " [0.04188044]\n",
      " [0.9240583 ]\n",
      " [0.16630271]\n",
      " [0.9713651 ]\n",
      " [0.04201908]\n",
      " [0.04133702]\n",
      " [0.04420199]\n",
      " [0.39678302]\n",
      " [0.7464085 ]\n",
      " [0.9722815 ]\n",
      " [0.09228178]\n",
      " [0.9722421 ]\n",
      " [0.05310144]\n",
      " [0.04199696]\n",
      " [0.04145423]\n",
      " [0.9725565 ]\n",
      " [0.9668134 ]\n",
      " [0.9615591 ]\n",
      " [0.04121407]\n",
      " [0.53736115]\n",
      " [0.04171398]\n",
      " [0.8899328 ]\n",
      " [0.88157445]\n",
      " [0.04232657]\n",
      " [0.9719168 ]\n",
      " [0.04263192]\n",
      " [0.14953807]\n",
      " [0.9008148 ]\n",
      " [0.10201554]\n",
      " [0.04132276]\n",
      " [0.04184483]\n",
      " [0.04252807]\n",
      " [0.07633394]\n",
      " [0.9724562 ]\n",
      " [0.04119749]\n",
      " [0.9683483 ]\n",
      " [0.97210664]\n",
      " [0.97271305]\n",
      " [0.9721535 ]\n",
      " [0.97216105]\n",
      " [0.9673923 ]\n",
      " [0.66857916]\n",
      " [0.9725033 ]\n",
      " [0.9723227 ]\n",
      " [0.04880255]\n",
      " [0.5122067 ]\n",
      " [0.8525529 ]\n",
      " [0.97208846]\n",
      " [0.97262716]\n",
      " [0.04326549]\n",
      " [0.13081942]\n",
      " [0.13896827]\n",
      " [0.04637706]\n",
      " [0.7462408 ]\n",
      " [0.96354944]\n",
      " [0.04119437]\n",
      " [0.04173661]\n",
      " [0.0863257 ]\n",
      " [0.0412247 ]\n",
      " [0.4829323 ]\n",
      " [0.22426318]\n",
      " [0.9710946 ]\n",
      " [0.04122093]\n",
      " [0.04163646]\n",
      " [0.12619735]\n",
      " [0.09887903]\n",
      " [0.9021074 ]\n",
      " [0.9591031 ]\n",
      " [0.0411978 ]\n",
      " [0.05142717]\n",
      " [0.04900185]\n",
      " [0.97198844]\n",
      " [0.04119344]\n",
      " [0.26461926]\n",
      " [0.04122346]\n",
      " [0.04141935]\n",
      " [0.20404401]\n",
      " [0.97118735]\n",
      " [0.9088662 ]\n",
      " [0.84520066]\n",
      " [0.9726108 ]\n",
      " [0.6791724 ]\n",
      " [0.04123051]\n",
      " [0.0415183 ]\n",
      " [0.9473501 ]\n",
      " [0.965379  ]\n",
      " [0.97270525]\n",
      " [0.9596272 ]\n",
      " [0.05044605]\n",
      " [0.9712314 ]\n",
      " [0.97241575]\n",
      " [0.09448123]\n",
      " [0.04123048]\n",
      " [0.04154829]\n",
      " [0.04214437]\n",
      " [0.9709373 ]\n",
      " [0.75372666]\n",
      " [0.9715882 ]\n",
      " [0.953472  ]\n",
      " [0.18453321]\n",
      " [0.05826754]\n",
      " [0.97197723]\n",
      " [0.97216165]\n",
      " [0.06795435]\n",
      " [0.9720718 ]\n",
      " [0.10038818]\n",
      " [0.20913719]\n",
      " [0.14780582]\n",
      " [0.04127811]\n",
      " [0.05498171]\n",
      " [0.07005111]\n",
      " [0.9701523 ]\n",
      " [0.04293271]\n",
      " [0.91791975]\n",
      " [0.9611845 ]\n",
      " [0.9712611 ]\n",
      " [0.4219868 ]\n",
      " [0.97262365]\n",
      " [0.9685457 ]\n",
      " [0.83111465]\n",
      " [0.8988906 ]\n",
      " [0.97167593]\n",
      " [0.04123361]\n",
      " [0.9727089 ]\n",
      " [0.9725996 ]\n",
      " [0.94442123]\n",
      " [0.04120226]\n",
      " [0.9724687 ]\n",
      " [0.9725563 ]\n",
      " [0.9076804 ]\n",
      " [0.96013504]\n",
      " [0.04166919]\n",
      " [0.04274914]\n",
      " [0.91783655]\n",
      " [0.97267896]\n",
      " [0.9727024 ]\n",
      " [0.04120874]\n",
      " [0.8366245 ]\n",
      " [0.9713776 ]\n",
      " [0.89000076]\n",
      " [0.950201  ]\n",
      " [0.94450617]\n",
      " [0.04236242]\n",
      " [0.04145122]\n",
      " [0.04120468]\n",
      " [0.06375539]\n",
      " [0.8952881 ]\n",
      " [0.28823635]\n",
      " [0.06650439]\n",
      " [0.07319952]\n",
      " [0.8743196 ]\n",
      " [0.972175  ]\n",
      " [0.24899784]\n",
      " [0.0413109 ]\n",
      " [0.04169454]\n",
      " [0.8563473 ]\n",
      " [0.04167262]\n",
      " [0.04835185]\n",
      " [0.9631364 ]\n",
      " [0.04129029]\n",
      " [0.97169703]\n",
      " [0.04130408]\n",
      " [0.04409328]\n",
      " [0.10321064]\n",
      " [0.11946475]\n",
      " [0.97248447]\n",
      " [0.04537891]\n",
      " [0.94945085]\n",
      " [0.0412825 ]\n",
      " [0.0550418 ]\n",
      " [0.04121283]\n",
      " [0.92348677]\n",
      " [0.04119646]\n",
      " [0.37479746]\n",
      " [0.20027065]\n",
      " [0.97270703]\n",
      " [0.9725029 ]\n",
      " [0.9215992 ]\n",
      " [0.65156615]\n",
      " [0.04154128]\n",
      " [0.06118413]\n",
      " [0.9726113 ]\n",
      " [0.23761201]\n",
      " [0.16950227]\n",
      " [0.97111815]\n",
      " [0.9725244 ]\n",
      " [0.9707393 ]\n",
      " [0.78803575]\n",
      " [0.04283497]\n",
      " [0.04720221]\n",
      " [0.8792913 ]\n",
      " [0.50721794]\n",
      " [0.8808828 ]\n",
      " [0.9726489 ]\n",
      " [0.97271407]\n",
      " [0.05762495]\n",
      " [0.04119352]\n",
      " [0.04383394]\n",
      " [0.04587242]\n",
      " [0.9491283 ]\n",
      " [0.9135449 ]\n",
      " [0.04430199]\n",
      " [0.9722107 ]\n",
      " [0.97178334]\n",
      " [0.4279464 ]\n",
      " [0.97026783]\n",
      " [0.90901613]\n",
      " [0.2321666 ]\n",
      " [0.0448168 ]\n",
      " [0.0588111 ]\n",
      " [0.6965405 ]\n",
      " [0.04147866]\n",
      " [0.04270216]\n",
      " [0.9718811 ]\n",
      " [0.04339201]\n",
      " [0.08996342]\n",
      " [0.8363752 ]\n",
      " [0.04253827]\n",
      " [0.96650267]\n",
      " [0.932425  ]\n",
      " [0.97162795]\n",
      " [0.9727145 ]\n",
      " [0.04192661]\n",
      " [0.05058996]\n",
      " [0.35850173]\n",
      " [0.9618661 ]\n",
      " [0.04119731]\n",
      " [0.0411963 ]\n",
      " [0.7746197 ]\n",
      " [0.05595968]\n",
      " [0.12813595]\n",
      " [0.06173104]\n",
      " [0.85148793]\n",
      " [0.9724586 ]\n",
      " [0.9726961 ]\n",
      " [0.0653416 ]\n",
      " [0.97024035]\n",
      " [0.97260994]\n",
      " [0.04333531]\n",
      " [0.21723983]\n",
      " [0.9635808 ]\n",
      " [0.04299478]\n",
      " [0.04122398]\n",
      " [0.97236884]\n",
      " [0.13072188]\n",
      " [0.04119221]\n",
      " [0.04254754]\n",
      " [0.04123663]\n",
      " [0.05233989]\n",
      " [0.97259945]\n",
      " [0.96844256]\n",
      " [0.9721812 ]\n",
      " [0.09644283]\n",
      " [0.5084671 ]\n",
      " [0.04164804]\n",
      " [0.7197844 ]\n",
      " [0.5654261 ]\n",
      " [0.15265125]\n",
      " [0.05132975]\n",
      " [0.26048055]\n",
      " [0.09411336]\n",
      " [0.9726939 ]\n",
      " [0.8815695 ]\n",
      " [0.04380172]\n",
      " [0.7839994 ]\n",
      " [0.96949154]\n",
      " [0.04122883]\n",
      " [0.40368637]\n",
      " [0.9726344 ]\n",
      " [0.9724095 ]\n",
      " [0.9264304 ]\n",
      " [0.96824765]\n",
      " [0.05857977]\n",
      " [0.05118437]\n",
      " [0.15559055]\n",
      " [0.34352994]\n",
      " [0.04126126]\n",
      " [0.95908433]\n",
      " [0.09144685]\n",
      " [0.8100828 ]\n",
      " [0.14698221]\n",
      " [0.07034639]\n",
      " [0.97148466]\n",
      " [0.06320566]\n",
      " [0.04120559]\n",
      " [0.9727091 ]\n",
      " [0.8988518 ]\n",
      " [0.55387324]\n",
      " [0.07706603]\n",
      " [0.8910182 ]\n",
      " [0.9726892 ]\n",
      " [0.0476073 ]\n",
      " [0.9695737 ]\n",
      " [0.04126967]\n",
      " [0.74619555]\n",
      " [0.9727116 ]\n",
      " [0.06622921]\n",
      " [0.75386417]\n",
      " [0.05334727]\n",
      " [0.9718215 ]\n",
      " [0.9717206 ]\n",
      " [0.04122514]\n",
      " [0.953693  ]\n",
      " [0.9725888 ]\n",
      " [0.95044136]\n",
      " [0.04460049]\n",
      " [0.66676617]\n",
      " [0.09470147]\n",
      " [0.9328495 ]\n",
      " [0.21362524]\n",
      " [0.04122734]\n",
      " [0.06156267]\n",
      " [0.05071022]\n",
      " [0.9235868 ]\n",
      " [0.04180956]\n",
      " [0.9693295 ]\n",
      " [0.04506195]\n",
      " [0.19168894]\n",
      " [0.04143835]\n",
      " [0.04138927]\n",
      " [0.63202   ]\n",
      " [0.0418302 ]\n",
      " [0.04132348]\n",
      " [0.24626963]\n",
      " [0.9726692 ]\n",
      " [0.04129519]\n",
      " [0.04608921]\n",
      " [0.9480722 ]\n",
      " [0.08848652]\n",
      " [0.97269356]\n",
      " [0.3242358 ]\n",
      " [0.04205874]\n",
      " [0.9278713 ]\n",
      " [0.9713016 ]\n",
      " [0.04232539]\n",
      " [0.10842575]\n",
      " [0.04191821]\n",
      " [0.15169972]\n",
      " [0.9708264 ]\n",
      " [0.04120559]\n",
      " [0.92863345]\n",
      " [0.8385402 ]\n",
      " [0.7818482 ]\n",
      " [0.84131527]\n",
      " [0.04120066]\n",
      " [0.97015876]\n",
      " [0.9122835 ]\n",
      " [0.84097517]\n",
      " [0.56573147]\n",
      " [0.27092728]\n",
      " [0.04121062]\n",
      " [0.96800905]\n",
      " [0.04133278]\n",
      " [0.6919435 ]\n",
      " [0.8173997 ]\n",
      " [0.12991694]\n",
      " [0.96803206]\n",
      " [0.8444481 ]\n",
      " [0.04336037]\n",
      " [0.04120184]\n",
      " [0.9698142 ]\n",
      " [0.04813849]\n",
      " [0.97264796]\n",
      " [0.04133404]\n",
      " [0.8436456 ]\n",
      " [0.97259754]\n",
      " [0.19071378]\n",
      " [0.05347417]\n",
      " [0.9594037 ]\n",
      " [0.21189885]\n",
      " [0.89060074]\n",
      " [0.158342  ]\n",
      " [0.04326194]\n",
      " [0.971899  ]\n",
      " [0.97259915]\n",
      " [0.13363889]\n",
      " [0.21441348]\n",
      " [0.33027297]\n",
      " [0.89258295]\n",
      " [0.05709226]\n",
      " [0.06063453]\n",
      " [0.10888981]\n",
      " [0.91236377]\n",
      " [0.0506947 ]\n",
      " [0.5081603 ]\n",
      " [0.9447305 ]\n",
      " [0.04154089]\n",
      " [0.0582092 ]\n",
      " [0.04119932]\n",
      " [0.0412124 ]\n",
      " [0.04147725]\n",
      " [0.278331  ]\n",
      " [0.97173315]\n",
      " [0.04163988]\n",
      " [0.10711957]\n",
      " [0.96540296]\n",
      " [0.09191143]\n",
      " [0.04143983]\n",
      " [0.04125518]\n",
      " [0.21847592]\n",
      " [0.97262734]\n",
      " [0.05125745]\n",
      " [0.97251016]\n",
      " [0.873115  ]\n",
      " [0.9659776 ]\n",
      " [0.04380314]\n",
      " [0.93837357]\n",
      " [0.44535178]\n",
      " [0.22885692]\n",
      " [0.04137842]\n",
      " [0.5139472 ]\n",
      " [0.6212098 ]\n",
      " [0.04131068]\n",
      " [0.04149248]\n",
      " [0.97101027]\n",
      " [0.97203565]\n",
      " [0.25514486]\n",
      " [0.93679595]\n",
      " [0.95774364]\n",
      " [0.0927523 ]\n",
      " [0.97221345]\n",
      " [0.96952873]\n",
      " [0.8097848 ]\n",
      " [0.0416121 ]\n",
      " [0.07824705]\n",
      " [0.9726501 ]\n",
      " [0.9722447 ]\n",
      " [0.04473906]\n",
      " [0.97236013]\n",
      " [0.96907395]\n",
      " [0.04362016]\n",
      " [0.04122433]\n",
      " [0.27531323]\n",
      " [0.8879366 ]\n",
      " [0.9507532 ]\n",
      " [0.04130076]\n",
      " [0.28237224]\n",
      " [0.04350442]\n",
      " [0.04130017]\n",
      " [0.05715691]\n",
      " [0.97178173]\n",
      " [0.96785617]\n",
      " [0.83127606]\n",
      " [0.04160643]\n",
      " [0.04122129]\n",
      " [0.0413294 ]\n",
      " [0.04914336]\n",
      " [0.05090016]\n",
      " [0.04206246]\n",
      " [0.0411934 ]\n",
      " [0.20766515]\n",
      " [0.04881182]\n",
      " [0.5821388 ]\n",
      " [0.3271319 ]\n",
      " [0.04440309]\n",
      " [0.6185046 ]\n",
      " [0.04851424]\n",
      " [0.90768844]\n",
      " [0.8481983 ]\n",
      " [0.04526634]\n",
      " [0.04148541]\n",
      " [0.928376  ]\n",
      " [0.97266465]\n",
      " [0.04119964]\n",
      " [0.0684495 ]\n",
      " [0.3459349 ]\n",
      " [0.18710972]\n",
      " [0.9723479 ]\n",
      " [0.97193027]\n",
      " [0.96948886]\n",
      " [0.64110357]\n",
      " [0.04120239]\n",
      " [0.04914292]\n",
      " [0.76069343]\n",
      " [0.04232622]\n",
      " [0.972546  ]\n",
      " [0.12981112]\n",
      " [0.05630779]\n",
      " [0.9292642 ]\n",
      " [0.1625735 ]\n",
      " [0.97244316]\n",
      " [0.10513183]\n",
      " [0.9722923 ]\n",
      " [0.96763235]\n",
      " [0.96075326]\n",
      " [0.9727045 ]\n",
      " [0.9725037 ]\n",
      " [0.9697096 ]\n",
      " [0.19312409]\n",
      " [0.08385085]\n",
      " [0.05247951]\n",
      " [0.07481848]\n",
      " [0.9725454 ]\n",
      " [0.04121608]\n",
      " [0.30407006]\n",
      " [0.96725374]\n",
      " [0.33269256]\n",
      " [0.04271837]\n",
      " [0.04231648]\n",
      " [0.04137568]\n",
      " [0.9724229 ]\n",
      " [0.5501659 ]\n",
      " [0.4035858 ]\n",
      " [0.04120458]\n",
      " [0.0516283 ]\n",
      " [0.3026181 ]\n",
      " [0.97106034]\n",
      " [0.97176033]\n",
      " [0.962299  ]\n",
      " [0.9125928 ]\n",
      " [0.04120878]\n",
      " [0.3314085 ]\n",
      " [0.04121293]\n",
      " [0.04455532]\n",
      " [0.554872  ]\n",
      " [0.12505145]\n",
      " [0.04355819]\n",
      " [0.05943243]\n",
      " [0.97271365]\n",
      " [0.9703453 ]\n",
      " [0.04495426]\n",
      " [0.9683535 ]\n",
      " [0.3726464 ]\n",
      " [0.04746534]\n",
      " [0.97270983]\n",
      " [0.96768737]\n",
      " [0.04232904]\n",
      " [0.32058585]\n",
      " [0.96952045]\n",
      " [0.05893473]\n",
      " [0.97155964]\n",
      " [0.61369246]\n",
      " [0.04120518]\n",
      " [0.04267211]\n",
      " [0.82705617]\n",
      " [0.9699517 ]\n",
      " [0.041254  ]\n",
      " [0.9725239 ]\n",
      " [0.97270674]\n",
      " [0.04379632]\n",
      " [0.2214746 ]\n",
      " [0.9683944 ]\n",
      " [0.97270703]\n",
      " [0.04627667]\n",
      " [0.04304539]\n",
      " [0.9725303 ]\n",
      " [0.9691365 ]\n",
      " [0.04386315]\n",
      " [0.9674706 ]\n",
      " [0.04710763]\n",
      " [0.97118056]\n",
      " [0.04124885]\n",
      " [0.97233635]\n",
      " [0.96846807]\n",
      " [0.85561645]\n",
      " [0.9142099 ]\n",
      " [0.9726842 ]\n",
      " [0.28372824]\n",
      " [0.14323281]\n",
      " [0.04150473]\n",
      " [0.04195271]\n",
      " [0.12366361]\n",
      " [0.97256327]\n",
      " [0.9007599 ]\n",
      " [0.8784815 ]\n",
      " [0.05544261]\n",
      " [0.04135894]\n",
      " [0.3139999 ]\n",
      " [0.9067965 ]\n",
      " [0.04119704]\n",
      " [0.9724689 ]\n",
      " [0.96444875]\n",
      " [0.93690515]\n",
      " [0.9085811 ]\n",
      " [0.7802871 ]\n",
      " [0.04385494]\n",
      " [0.23945087]\n",
      " [0.04132732]\n",
      " [0.9712022 ]\n",
      " [0.9718081 ]\n",
      " [0.7923768 ]\n",
      " [0.672161  ]\n",
      " [0.32440653]\n",
      " [0.07296699]\n",
      " [0.10422186]\n",
      " [0.05412996]\n",
      " [0.9726835 ]\n",
      " [0.07010865]\n",
      " [0.14436416]\n",
      " [0.9724955 ]\n",
      " [0.96450835]\n",
      " [0.19476773]\n",
      " [0.9672091 ]\n",
      " [0.04293399]\n",
      " [0.04155498]\n",
      " [0.04414655]\n",
      " [0.09474681]\n",
      " [0.9718036 ]\n",
      " [0.7972104 ]\n",
      " [0.9720269 ]\n",
      " [0.04378356]\n",
      " [0.07708034]\n",
      " [0.04186232]\n",
      " [0.12642394]\n",
      " [0.04184506]\n",
      " [0.07059909]\n",
      " [0.9726938 ]\n",
      " [0.8930559 ]\n",
      " [0.33192387]\n",
      " [0.04125462]]\n"
     ]
    }
   ],
   "source": [
    "a_3 = modelo.predict(X_train)\n",
    "print(f\"As previsões para o valor da probabilidade de x_1 pertencer à classe 1 são: \\n{a_3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "previsoes_treinamento = (a_3 >= 0.5).astype(int)\n",
    "previsoes_treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.903"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conta=0\n",
    "for i in range (len(previsoes_treinamento)):\n",
    "    if previsoes_treinamento[i] == y_train[i]: \n",
    "        conta +=1\n",
    "\n",
    "conta/len(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos criar um conjunto de teste da mesma maneira que criamos o de treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "classes = 2\n",
    "m = 200\n",
    "centers = [[-5, -5, -5], [5, 5, 5]]\n",
    "std = 7.0\n",
    "X_test, y_test = make_blobs(n_samples=m, centers=centers, cluster_std=std,random_state=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "a_3 = modelo.predict(X_test)\n",
    "previsoes_testes = (a_3 >= 0.5).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.895"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conta=0\n",
    "\n",
    "for i in range (len(previsoes_testes)):\n",
    "    if previsoes_testes[i] == y_test[i]: \n",
    "        conta +=1\n",
    "\n",
    "conta/len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funções de Ativação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Linear: $$a=g(z)=z$$\n",
    "\n",
    "- Sigmoid: $$a = g(z)=\\frac{1}{1+e^{-z}}$$\n",
    "\n",
    "- Relu: $$a = g(z)= \\max(0,z)$$\n",
    "\n",
    "- Leaky ReKY: $$a = g(z)= \\max(0.1z , z)$$\n",
    "\n",
    "- Softmax (multiclasse, com $K$ classes): $$a = g(z_i) = \\frac{e^{z_i}}{\\sum_j^Ke^{z_j}}$$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exemplo do uso da função de ativação Softmax:**\n",
    "\n",
    "<img src = \"softmax.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Notação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A seguinte notação será utilizada para uma rede neural multicamada:\n",
    "\n",
    "- O número de camadas na rede é dado por $L$ e o número de neurônios em uma camada $l$ é dado por $n^{[l]}$ , sendo $n^{[0]}=n$ o número de atributos.\n",
    "- Um exemplo de treinamento é representado por um vetor coluna de $n$  atributos.\n",
    "\n",
    "$$ \\vec{x}^{(i)} \\in \\mathbb{R}^{n^{[0]}} = [x_1^{(i)}, x_2^{(i)}, ..., x_n^{(i)}]^T $$\n",
    "\n",
    "- A matriz $ \\mathbf{X} \\in \\mathbb{R}^{n^{[0]} \\times m}$ organiza cada um dos $m$ exemplos de treinamento em uma coluna, assim, $\\mathbf{X}_{:,i} = x^{(i)}$.\n",
    "\n",
    "- $y^{(i)}$ representa um rótulo atribuído ao exemplo $\\vec{x}^{(i)}$. O vetor $\\vec{y} = [y^{(i)},…,y^{(m)}] $ representa os rótulos do conjunto de treinamento. \n",
    "\n",
    "- Uma matriz $\\mathbf{W}^{[l]} \\in \\mathbb{R}^{n^{[l-1]} \\times n^{[l]}}$ representa os pesos utilizados para ponderar a entrada de uma camada $l$ com uma equação linear do tipo: $w \\cdot x+b$. \n",
    "\n",
    "- A entrada da matriz na linha $i$ e coluna $j$, $W_{i,j}^{[l]}$ , representa o peso associado a uma entrada no neurônio $j$  da camada $l$ que corresponde a uma saída do neurônio $i$ da camada $(l-1)$. \n",
    "\n",
    "- O vetor coluna $\\vec{b}^{[l]}$  recebe os valores dos interceptos das $n^{[l]}$  equações lineares correspondentes às entradas dos neurônios da camada $l$.\n",
    "\n",
    "- $\\vec{z}^{[l]} = \\mathbf{W}^{[l]^T} \\cdot \\vec{a}^{[l-1]} + \\vec{b}^{[l]}$, onde $\\vec{z}^{[l]} \\in \\mathbb{R}^{n^{[l]}}$, representa um vetor coluna com a ponderação das entradas nos neurônios da camada $l$. Na primeira camada intermediária, o exemplo de treinamento é ponderado, $ \\vec{a}^{[0]} = \\vec{x}$.\n",
    "\n",
    "- Uma matriz $\\mathbf{Z}^{[l]} \\in \\mathbb{R}^{n^{[l]} \\times m} $ representa as ponderações das entradas para os $m$ diferentes exemplos do conjunto de treinamento Dessa forma: $\\mathbf{A}^{[0]} = \\mathbf{X}$. \n",
    "\n",
    "- $\\vec{a}^{[l]} \\in \\mathbb{R}^{n^{[l]}}$ representa a saída da função de ativação $g^[l]$ aplicada na camada $l$. Assim, para uma camada $l$ temos: $\\vec{a}^{[l]}=g^{[l]} (\\vec{z}^{[l]})$.\n",
    "\n",
    "- Uma matriz $\\mathbf{A}^{[l]} \\in \\mathbb{R}^{n^{[l]} \\times m}$ representa as saídas das funções de ativação em cada camada $l$ (linhas) para os $m$ exemplos de treinamento (colunas).\n",
    "\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e4cce46d6be9934fbd27f9ca0432556941ea5bdf741d4f4d64c6cd7f8dfa8fba"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
